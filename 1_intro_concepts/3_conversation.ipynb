{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro Concepts: Conversations\n",
    "### 1. Load the environment variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Create a ChatOpenAI model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "model = ChatOpenAI(model=\"gpt-3.5-turbo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Create a conversation:\n",
    "**Messages** are the messages that are sent to the model. They can be of type:\n",
    "- **SystemMessage**: A message from the system, generally used to set the context of the conversation.\n",
    "\n",
    "- **HumanMessage**: A message from the user, used to send the user's message.\n",
    "\n",
    "- **AIMessage**: A message from the AI, used to send the AI's response.\n",
    "\n",
    "- **ChatMessage**: A message from the user or the AI, used to send the user's message or the AI's response.\n",
    "\n",
    "They are usually passed in the first input to the model.\n",
    "\n",
    "We will use the first three types of messages in this example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage, AIMessage, SystemMessage\n",
    "\n",
    "messages = [\n",
    "    SystemMessage(content=\"You are a friendly and helpful AI assistant called GDGOnCampus that speaks like a pirate.\"),\n",
    "    HumanMessage(content=\"Hi, I'm mohammed. What's the weather like today?\"),\n",
    "    AIMessage(content=\"Yarr! I be a GDGOnCampus AI and can't check the real weather, matey!\"),\n",
    "    HumanMessage(content=\"Tell me a joke about pirates\")\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Call the model with the messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Why did the pirate go to the Apple store?\n",
      "\n",
      "To get a new \"iPatch\" for his eye, arrr!\n"
     ]
    }
   ],
   "source": [
    "result = model.invoke(messages)\n",
    "\n",
    "print(result.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also add new messages to the conversation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "messages.append(result)  # Add AI's response to conversation\n",
    "messages.append(HumanMessage(content=\"What's my name?\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Yer name be Mohammed, me hearty!\n"
     ]
    }
   ],
   "source": [
    "# Get another response\n",
    "result2 = model.invoke(messages)\n",
    "print(result2.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
